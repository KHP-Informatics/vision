{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6b21cb",
   "metadata": {},
   "source": [
    "STM_bitermplus_Tutorial\n",
    "========\n",
    "\n",
    "Model fitting\n",
    "-------------\n",
    "\n",
    "Here is a simple example of model fitting.\n",
    "It is supposed that you have already gone through the preprocessing\n",
    "stage: cleaned, lemmatized or stemmed your documents, and removed stop words.\n",
    "\n",
    ".. code-block:: python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bitermplus\n",
    "import bitermplus as btm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('All interviewees responses and the corresponding representative words_withoutNONE_updatedV14.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d32005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[['ids', 'diagnosis', 'section', 'pilot_number', 'inter_time', 'response',\n",
    "       'response_lemar', 'new_response', 'Topic most represented',\n",
    "       'Topic and its most representative words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a500e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset='new_response')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('All interviewees responses and the corresponding representative words_withoutNONE_updatedV11.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b70958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = pd.DataFrame(range(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93adb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['new_response'].str.strip().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "# new_stopwords = [\"um\", \"oh\", \"okay\", \"mhm\",\"ah\",\"uh\",\"yes\",\"get\",'yep',\"yeah\",\"no\",\"hm\",\"wow\",'.','?','-','--',':','mm','Mm','Oop']\n",
    "# stopwords.extend(new_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing documents, obtaining full vocabulary and biterms\n",
    "# Internally, btm.get_words_freqs uses CountVectorizer from sklearn\n",
    "# You can pass any of its arguments to btm.get_words_freqs\n",
    "# For example, you can remove stop words:\n",
    "# stop_words = stopwords\n",
    "X, vocabulary, vocab_dict = btm.get_words_freqs(texts)\n",
    "docs_vec = btm.get_vectorized_docs(texts, vocabulary)\n",
    "biterms = btm.get_biterms(docs_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ba942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing and running model\n",
    "# Optimal model selection\n",
    "# Calculating metrics¶\n",
    "# To calculate perplexity, we must provide documents vs topics probability matrix (p_zd) \n",
    "# that we calculated at the previous step.\n",
    "   \n",
    "metrics=[]\n",
    "for topic_num in range(2,15):\n",
    "    print(topic_num)\n",
    "    model = btm.BTM(X, vocabulary, seed=12321, T=topic_num, M=20, alpha=50/10, beta=0.01)\n",
    "    model.fit(biterms, iterations=20)\n",
    "    # Get a phi matrix\n",
    "    #phi = tmp.get_phi(model)\n",
    "    #entropy = tmp.entropy(phi)\n",
    "    perplexity = model.perplexity_\n",
    "    coherence = model.coherence_\n",
    "    metrics.append([topic_num,perplexity,coherence])\n",
    "metrics=pd.DataFrame(metrics)\n",
    "metrics.columns=['Topic number', 'perplexity','coherence']\n",
    "metrics['coherence mean']=[np.mean(x) for x in metrics['coherence'].tolist()]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2b98f",
   "metadata": {},
   "source": [
    "##  Choosing the Best Coherence Score\n",
    "There is no one way to determine whether the coherence score is good or bad. The score and its value depend on the data that it’s calculated from. For instance, in one case, the score of 0.5 might be good enough but in another case not acceptable. The only rule is that we want to maximize this score.\n",
    "\n",
    "Usually, the coherence score will increase with the increase in the number of topics. This increase will become smaller as the number of topics gets higher. The trade-off between the number of topics and coherence score can be achieved using the so-called elbow technique. The method implies plotting coherence score as a function of the number of topics. We use the elbow of the curve to select the number of topics.\n",
    "\n",
    "The idea behind this method is that we want to choose a point after which the diminishing increase of coherence score is no longer worth the additional increase of the number of topics. The example of elbow cutoff at n\\_topics = 3 is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c36d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(metrics)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e581a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmplot as tmp\n",
    "optimal_topic_number=10\n",
    "model = btm.BTM(X, vocabulary, seed=1234, T=optimal_topic_number, M=20)\n",
    "model.fit(biterms, iterations=500)\n",
    "# Get a phi matrix\n",
    "phi = tmp.get_phi(model)\n",
    "entropy = tmp.entropy(phi)\n",
    "\n",
    "# Inference\n",
    "# ---------\n",
    "\n",
    "# Now, we will calculate documents vs topics probability matrix (make an inference).\n",
    "\n",
    "# .. code-block:: python\n",
    "\n",
    "p_zd = model.transform(docs_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best topic for each document\n",
    "best_topics = [np.argmax(doc_topics) for doc_topics in p_zd]\n",
    "\n",
    "# Print the best topic for each document\n",
    "new_file = open('best_topic_for_each_doc.csv','wt')\n",
    "for i, topic in enumerate(best_topics):\n",
    "     #print(f\"Document {i}: Topic {topic}\")\n",
    "    new_file.write(str(i)+','+str(topic)+'\\n')\n",
    "print(model.matrix_words_topics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmplot as tmp\n",
    "\n",
    "# Train or import a trained model here\n",
    "\n",
    "model = btm.BTM(X, vocabulary, seed=1234, T=10, M=20) #, alpha=50/10, beta=0.01\n",
    "model.fit(biterms, iterations=500)\n",
    "    \n",
    "# Get a phi matrix\n",
    "phi = tmp.get_phi(model)\n",
    "entropy = tmp.entropy(phi)\n",
    "print(entropy)\n",
    "\n",
    "\n",
    "theta = tmp.get_theta(model)\n",
    "print(theta)\n",
    "\n",
    "# Calculate terms probabilities\n",
    "# Do not forget to pass topic id with `topic` argument\n",
    "terms_probs = tmp.calc_terms_probs_ratio(phi, topic=0, lambda_=0.9)\n",
    "print(terms_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the top 15 words for each topic\n",
    "print(len(model.labels_))\n",
    "labels = pd.DataFrame(model.labels_)\n",
    "new_id = pd.DataFrame(range(len(model.labels_)))\n",
    "df_with_label=pd.DataFrame()\n",
    "df_with_label['index']=new_id\n",
    "df_with_label['topic_label']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b62048",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_with_label = pd.merge(df,df_with_label,on='index')\n",
    "print(new_df_with_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_with_label.to_excel('All interviewees responses_withoutNONE_updatedV17_with_BTM.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff133b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_with_label.to_csv('All interviewees responses_withoutNONE_updatedV17_with_BTM.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d37a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_df_with_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b72256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tmplot\n",
    "import tmplot as tmp\n",
    "\n",
    "# Run the interactive report interface\n",
    "tmp.report(model=model, docs=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting topics as a scatter plot\n",
    "topics_coords = tmp.prepare_coords(model)\n",
    "tmp.plot_scatter_topics(topics_coords, size_col='size', label_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting terms probabilities\n",
    "\n",
    "nf =open('topic_wordsV3.csv','wt')\n",
    "nf.write('topic,reprensentative_words'+'\\n')\n",
    "for i in range(10):\n",
    "    terms_probs = tmp.calc_terms_probs_ratio(phi, topic=i, lambda_=1)\n",
    "    #print( terms_probs['Terms'][0:30])\n",
    "    words = ' '.join(row for row in terms_probs['Terms'][0:20])\n",
    "    print(i,words)\n",
    "    nf.write(str(i)+','+str(words)+'\\n')\n",
    "    #terms_probs.to_csv('Topic_'+str(i)+'terms and probability.csv',index=False)\n",
    "    #tmp.plot_terms(terms_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words_df = pd.read_csv('topic_wordsV3.csv')\n",
    "print(topic_words_df.shape)\n",
    "print(topic_words_df.columns)\n",
    "topic_words_df. rename(columns = {'topic':'topic_label'}, inplace = True)\n",
    "print(topic_words_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82641e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_with_label.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_label_topicwords = pd.merge(new_df_with_label,topic_words_df,on='topic_label',how='left')\n",
    "print(df_with_label_topicwords.head())\n",
    "print(df_with_label_topicwords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8addcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_label_topicwords.to_excel('All interviewees responses_withoutNONE_updatedV14_with_BTM_b.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = (df_with_label_topicwords[['ids','topic_label']]).groupby('topic_label').count()\n",
    "display(counts_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
